SVM

Best Parameters
C	2.5
degree	1
kernel	rbf
max_iter	2000
random_state	1
tol	0.0005

Confusion Matrix
95	13	
13	81	

Model Result
              precision    recall  f1-score   support

         0.0       0.88      0.88      0.88       108
         1.0       0.86      0.86      0.86        94

   micro avg       0.87      0.87      0.87       202
   macro avg       0.87      0.87      0.87       202
weighted avg       0.87      0.87      0.87       202



Decision Tree

Best Parameters
criterion	entropy
random_state	1

Confusion Matrix
82	26	
19	75	

Model Result
              precision    recall  f1-score   support

         0.0       0.81      0.76      0.78       108
         1.0       0.74      0.80      0.77        94

   micro avg       0.78      0.78      0.78       202
   macro avg       0.78      0.78      0.78       202
weighted avg       0.78      0.78      0.78       202



KNN

Best Parameters
algorithm	ball_tree
n_neighbors	2

Confusion Matrix
96	12	
23	71	

Model Result
              precision    recall  f1-score   support

         0.0       0.81      0.89      0.85       108
         1.0       0.86      0.76      0.80        94

   micro avg       0.83      0.83      0.83       202
   macro avg       0.83      0.82      0.82       202
weighted avg       0.83      0.83      0.83       202



Logistic Regression

Best Parameters
C	1.0
max_iter	400
multi_class	multinomial
random_state	1
solver	saga
tol	0.0005

Confusion Matrix
79	29	
14	80	

Model Result
              precision    recall  f1-score   support

         0.0       0.85      0.73      0.79       108
         1.0       0.73      0.85      0.79        94

   micro avg       0.79      0.79      0.79       202
   macro avg       0.79      0.79      0.79       202
weighted avg       0.80      0.79      0.79       202



Random Forest

Best Parameters
criterion	entropy
n_estimators	150
random_state	1

Confusion Matrix
98	10	
14	80	

Model Result
              precision    recall  f1-score   support

         0.0       0.88      0.91      0.89       108
         1.0       0.89      0.85      0.87        94

   micro avg       0.88      0.88      0.88       202
   macro avg       0.88      0.88      0.88       202
weighted avg       0.88      0.88      0.88       202



XGBoost

Best Parameters
booster	dart
learning_rate	0.1
n_estimators	150
objective	binary:logitraw
random_state	1
subsample	0.9

Confusion Matrix
97	11	
20	74	

Model Result
              precision    recall  f1-score   support

         0.0       0.83      0.90      0.86       108
         1.0       0.87      0.79      0.83        94

   micro avg       0.85      0.85      0.85       202
   macro avg       0.85      0.84      0.84       202
weighted avg       0.85      0.85      0.85       202



